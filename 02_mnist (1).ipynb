{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OECyOwdHPNqC"
      },
      "source": [
        "## Обучаем первую модель на MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUFQmv7IPNqE"
      },
      "source": [
        "План на сегодня: пишем первый пайплайн для обучения\n",
        "\n",
        "1. Пытаемся понять, какие компоненты нам нужны для обучения любой модели\n",
        "2. Выясняем, что многое уже есть в Pytorch\n",
        "3. Собираем наш первый скрипт для обучения на датасете MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8hKqhpxPNqF"
      },
      "source": [
        "### 1. Разбираемся с данными\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5DG8upePNqF"
      },
      "source": [
        "#### 1.1. Организуем доступ к данным с `torch.utils.data.Dataset`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RHrTpQmPNqF"
      },
      "source": [
        "Датасет в pytorch - это объект класса, в котором реализовано два обязательных метода: `__getitem__(self, index: int)` (получение одиночного примера по индексу) и `__len__(self)` (получение общего количества примеров). Этих методов достаточно, чтобы разбивать датасет на минибатчи  - это работу делает класс `torch.utils.DataLoader` с помощью различных семплеров, с ними мы понакомимся позже"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mfK9MbQPNqG",
        "outputId": "dfdbf96a-676c-45e7-a014-8c6f7b093282"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a6b2c154a10>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGdfpc2IPNqG",
        "outputId": "60a7ac15-7b8a-4e01-c9f1-d7262a2af820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 1, 2]), tensor(2))\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, n: int) -> None:\n",
        "        super().__init__()\n",
        "        self.data = torch.arange(n * 3).view((n, 3))\n",
        "        self.labels = torch.randint(0, 5, size=(n,))\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        return self.data[index], self.labels[index]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "dataset = MyDataset(n=10)\n",
        "print(dataset[0])\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQowv57aPNqH"
      },
      "source": [
        "Итерируемся по датасету:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gBAHC4fPNqH",
        "outputId": "42027129-30b3-4dcf-e01c-a08f79f874a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0, 1, 2]), tensor(3))\n",
            "(tensor([3, 4, 5]), tensor(4))\n",
            "(tensor([6, 7, 8]), tensor(0))\n",
            "(tensor([ 9, 10, 11]), tensor(4))\n",
            "(tensor([12, 13, 14]), tensor(1))\n",
            "(tensor([15, 16, 17]), tensor(2))\n",
            "(tensor([18, 19, 20]), tensor(0))\n",
            "(tensor([21, 22, 23]), tensor(0))\n",
            "(tensor([24, 25, 26]), tensor(2))\n",
            "(tensor([27, 28, 29]), tensor(1))\n"
          ]
        }
      ],
      "source": [
        "dataset = MyDataset(10)\n",
        "for i in range(len(dataset)):\n",
        "    print(dataset[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxMhh64-PNqH"
      },
      "source": [
        "#### 1.2. Пакуем данные в батчи с `torch.utils.data.Dataloader`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OUP9Q6HPNqH"
      },
      "source": [
        "У `torch.utils.data.Dataloader` много аргументов, на практике чаще всего используются\n",
        "- `dataset` - объект, поддерживающий методы `__getitem__` и `__len__` (вопрос: можно ли передать список? словарь? множество?)\n",
        "- `batch_size` - размер мини-батча\n",
        "- `shuffle` - нужно ли перетасовать индексы перед нарезкой на минибатчи (это всегда стоит делать с обучающими данными, почему?)\n",
        "- `num_workers` - количество процессов, которые будут загружать данные - иногда позволяет ускорить обучение (подумайте, в каком случае?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUpPZ_uRPNqI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "my_loader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    # drop_last=\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2z3KXJKPNqI",
        "outputId": "1fcfaec7-d5f7-42ab-9552-d7cf3b13cc63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[24, 25, 26],\n",
            "        [ 6,  7,  8],\n",
            "        [21, 22, 23],\n",
            "        [15, 16, 17]])\n",
            "tensor([2, 0, 0, 2])\n"
          ]
        }
      ],
      "source": [
        "for i, batch in enumerate(my_loader):\n",
        "    x, y = batch\n",
        "    if i == 0:\n",
        "        print(x)\n",
        "        print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-JdnqoIPNqI"
      },
      "source": [
        "#### 1.3. Посмотрим на MNIST\n",
        "\n",
        "- какие атрибуты есть у объекта `torchvision.datasets.MNIST`?\n",
        "- как выглядит одно наблюдение?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD2wV2hoPNqI",
        "outputId": "002706fe-82f3-4339-e007-0f291194d07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 34336141.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1098796.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 9345054.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3226715.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_dataset = datasets.MNIST(\n",
        "    \"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),  # что это?\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    \"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOsnsfpaPNqI",
        "outputId": "d003ae2c-719c-4f87-a7e9-6b0ba68e76c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "isinstance(train_dataset, Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02NQtCbOPNqI",
        "outputId": "12e35be9-4a45-4f82-828d-3b7ef7ec1a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "x, y = train_dataset[0]\n",
        "print(x.shape)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ParcQFHXPNqI"
      },
      "source": [
        "**Задание 1 (1 балл)**. Используя `matplotlib`, выведите по одному примеру изображения для всех классов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_UewkpLPNqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "c7744f94-f0b3-4215-9cf4-0838a49d4d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (_, _) = mnist.load_data()\n",
        "\n",
        "# Создаем список для хранения примеров каждого класса\n",
        "classes = np.unique(train_labels)\n",
        "class_examples = {}\n",
        "\n",
        "# Отбираем по одному примеру каждого класса\n",
        "for label in classes:\n",
        "    idx = np.where(train_labels == label)[0][0]\n",
        "    class_examples[label] = train_images[idx]\n",
        "\n",
        "# Выводим изображения\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i, (label, image) in enumerate(class_examples.items()):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f'Class {label}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqdEZrPiPNqJ"
      },
      "source": [
        "Попробуем получить минибатч:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe2xOT-jPNqJ"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOfRHY7jPNqJ"
      },
      "source": [
        "Что возвращает `iter()`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVvklwYvPNqJ",
        "outputId": "1a84d53e-cc24-4b89-c967-cc700aaf7737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 28, 28])\n",
            "torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "batch: tuple[torch.Tensor, torch.Tensor] = next(iter(train_loader))\n",
        "x, y = batch\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLuWmNhSPNqJ"
      },
      "source": [
        "Со свёрточными сетями мы познакомимся позже, сейчас же мы будем экспериментировать с обычными полносвязными сетями, но для этого нам нужно будет преобразовать форму батча из `(batch_size, channels, width, height)` в `(batch_size, channels * width * height)`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvsKkQVDPNqJ"
      },
      "source": [
        "**Задание 2 (1 балл)**. Есть несколько способов изменить форму (shape) тензора. Приведите все знаковые вам способы привести батч с изображениями в форму `(batch_size, channels * width * height)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BRfYfK6PNqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fa521eda-b875-4fb6-8573-8bbdfdfd90f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n.view() \\n.reshape() \\n.flatten() \\n.permute() \\n.contiguous() \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "batch_size, channels, width, height = x.shape\n",
        "input_dim = channels * width * height\n",
        "\"\"\"\n",
        ".view()\n",
        ".reshape()\n",
        ".flatten()\n",
        ".permute()\n",
        ".contiguous()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRnK4mviPNqJ"
      },
      "source": [
        "Ура, с данными вроде разобрались! Теперь разберёмся с моделью"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BV-t-pxPNqJ"
      },
      "source": [
        "### 2. Реализуем модель с помощью `torch.nn.Module`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCL2_m-JPNqJ"
      },
      "source": [
        "#### 2.1. Описываем параметры модели и прямой проход"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roZjsk21PNqK"
      },
      "source": [
        "Для простоты будем строить небольшую нейронку из двух полносвязных слоёв и `tanh` в качестве функции активации.\n",
        "\n",
        "$\\text{logits} = w_2^T(\\tanh(w_1^T x + b_1)) + b_2$\n",
        "\n",
        "Какие параметры должны быть в линейном слое?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tWyDNbBPNqK"
      },
      "outputs": [],
      "source": [
        "hidden_dim = 128  # размерность скрытого слоя\n",
        "n_classes = 10\n",
        "\n",
        "# первый слой\n",
        "w1 = torch.randn((input_dim, hidden_dim), requires_grad=True)\n",
        "b1 = torch.randn(hidden_dim, requires_grad=True)\n",
        "\n",
        "# второй слой\n",
        "w2 = torch.randn((hidden_dim, n_classes), requires_grad=True)\n",
        "b2 = torch.randn(n_classes, requires_grad=True)\n",
        "\n",
        "h = x.flatten(1) @ w1 + b1\n",
        "print(h.grad_fn)\n",
        "print(h.shape)\n",
        "\n",
        "# применяем нелинейность перед применением следующего слоя\n",
        "h = h.tanh()\n",
        "\n",
        "h = h @ w2 + b2\n",
        "print(h.grad_fn)\n",
        "print(h.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Frf8HKjkPNqK"
      },
      "outputs": [],
      "source": [
        "h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjmU0S91PNqK"
      },
      "source": [
        "Из этих выходных данных нам хотелось бы получить вероятностное распределение над возможными классами, то есть нужно как-то нормализовать эти активации, для этого обычно используется функция `softmax`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMLIGqlWPNqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c895b89f-3428-483b-c446-a3c682836da6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0875, 0.1361, 0.3852, 0.0321, 0.1009, 0.1273, 0.0733, 0.0299, 0.0156,\n",
              "        0.0121])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "z = torch.randn(10)\n",
        "torch.softmax(z, 0)\n",
        "# zz = torch.exp(z) / torch.exp(z).sum()\n",
        "# zz.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKdHBBaPNqK"
      },
      "source": [
        "Применим к нашим данным:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3vcWlSfPNqK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "550ed2d9-6400-491c-e36b-d14b5ddf248f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'h' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-0bbea8a895c7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ],
      "source": [
        "h.softmax(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEIBjx8rPNqK"
      },
      "source": [
        "Обратите внимание: классы получились совсем не равновероятны, хотя мы ещё не учили модель. Подумайте, почему так произошло?\n",
        "Подробнее это мы обсудим на следующей практике."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "letuNX_wPNqK"
      },
      "source": [
        "Параметры нашей модели находятся в глобальной области видимости. Решение - спрятать всё внутрь класса-наследника `torch.nn.Module`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aowbQzF4PNqK"
      },
      "source": [
        "#### 2.2. Реализуем двуслойный перцептрон как наследник `nn.Module`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAyRPR9oPNqO"
      },
      "source": [
        "**Задание 3 (1 балл)**. Прочитайте документацию к классам `torch.nn.Module` и `torch.nn.Parameter`. Почему при задании параметров модели не стоит их создавать просто как `torch.tensor(..., requires_grad=True)`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7atzxf70PNqO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0a1b82e1-a29e-4548-9498-19efad2865f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Использование torch.tensor(..., requires_grad=True) не регистрирует тензор как параметр модели.\\nЗначит оптимизаторы и другие механизмы не будут знать,что этот тензор нужно обновлять во время обратного распространения.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\"\"\"Использование torch.tensor(..., requires_grad=True) не регистрирует тензор как параметр модели.\n",
        "Значит оптимизаторы и другие механизмы не будут знать,что этот тензор нужно обновлять во время обратного распространения.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxJ-pRegPNqO"
      },
      "source": [
        "**Задание 4 (1 балл)**. Чтобы сделать наш модуль рабочим, нужно определить два метода: `__init__` и `forward`. Реализуйте метод `forward`, который возвращает логиты, т. е. выход последнего линейного слоя без применения функции активации `softmax`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DurLvyLAPNqO"
      },
      "outputs": [],
      "source": [
        "class SimpleNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
        "        super().__init__()\n",
        "        self.w1 = torch.nn.Parameter(torch.randn(input_dim, hidden_dim))\n",
        "        self.b1 = torch.nn.Parameter(torch.randn(hidden_dim))\n",
        "\n",
        "        self.w2 = torch.nn.Parameter(torch.randn(hidden_dim, output_dim))\n",
        "        self.b2 = torch.nn.Parameter(torch.randn(output_dim))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        hidden = torch.matmul(x, self.w1) + self.b1\n",
        "        hidden = torch.relu(hidden)\n",
        "        logits = torch.matmul(hidden, self.w2) + self.b2\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVUMSWw6PNqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc9caa8-4af1-4ae7-8e83-ab453e1a2fa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model = SimpleNet(input_dim, hidden_dim, n_classes)\n",
        "model(x).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9kNjllFPNqO"
      },
      "source": [
        "Параметры модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlaIsuDFPNqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46f1555-beb4-4d04-e156-87951983d378"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('w1',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.4833,  1.1003,  1.6497,  ..., -0.4619,  0.3176,  0.3544],\n",
              "          [ 0.1323, -0.3789, -0.2160,  ..., -0.4942,  0.5313,  0.0694],\n",
              "          [-1.9792, -0.8956, -0.3710,  ..., -0.8225,  0.8167, -0.7712],\n",
              "          ...,\n",
              "          [-0.2524,  1.3724,  0.7869,  ..., -0.7087,  1.0261,  0.0431],\n",
              "          [ 1.0059,  0.5968, -2.6199,  ...,  0.5565, -0.6058,  0.3181],\n",
              "          [ 0.3067, -1.1977,  0.8383,  ...,  0.0406,  0.0630,  0.0855]],\n",
              "         requires_grad=True)),\n",
              " ('b1',\n",
              "  Parameter containing:\n",
              "  tensor([ 1.1557e+00, -4.4822e-01,  1.9142e-01, -1.3616e+00,  7.1722e-01,\n",
              "           6.6379e-01, -6.1405e-01,  1.3502e+00,  5.9717e-01, -1.1031e+00,\n",
              "          -4.8588e-01, -1.4613e+00, -8.7228e-01,  8.9916e-01,  5.5902e-01,\n",
              "          -1.4034e+00, -4.4950e-02,  2.7086e-02, -1.2089e+00, -2.0392e-01,\n",
              "          -4.3619e-01, -4.1470e-04,  1.7490e+00, -1.6310e-01, -1.5554e+00,\n",
              "          -1.2879e+00, -1.5209e+00, -8.8056e-01,  1.8646e-02,  6.7518e-01,\n",
              "           1.0008e+00,  2.6435e+00,  1.8769e-01, -2.5043e+00,  6.9530e-01,\n",
              "           4.6901e-01, -1.7589e+00,  7.6134e-01, -8.3427e-01,  6.0055e-01,\n",
              "          -1.1446e+00, -1.2434e-01, -2.7047e-01,  8.3484e-01,  2.2499e+00,\n",
              "           8.1904e-02, -1.0347e+00, -4.1888e-02,  2.0093e+00,  5.0409e-02,\n",
              "           1.4091e+00,  4.1648e-02, -2.2337e-02,  1.0475e+00,  2.1332e-02,\n",
              "           1.1428e+00,  8.6800e-01, -1.9020e+00,  1.4810e-01, -9.7854e-01,\n",
              "           2.5342e-01,  3.9251e-01, -1.2603e+00, -1.5347e+00, -8.9366e-01,\n",
              "          -8.5602e-01,  5.5393e-01, -3.6713e-01,  2.7323e-01,  3.5508e-02,\n",
              "          -3.4361e-01, -2.0425e+00, -7.2689e-01,  1.6579e+00,  1.4123e+00,\n",
              "          -6.7296e-01, -1.6095e+00, -3.1187e-01, -1.1032e+00, -4.0689e-02,\n",
              "          -7.2346e-01,  9.1853e-01, -1.0466e-01, -5.0028e-01,  3.5403e-01,\n",
              "          -8.5942e-01,  2.1001e-01,  1.0709e-02, -9.0711e-01, -2.3880e-01,\n",
              "          -2.3605e+00, -2.6509e-01, -2.9011e+00, -4.0221e-01,  6.2128e-01,\n",
              "           4.7710e-01, -1.9940e+00,  2.3552e+00, -8.2786e-01, -1.4486e+00,\n",
              "          -9.2680e-01, -2.3931e+00, -6.0513e-02, -8.9464e-01,  2.5876e-01,\n",
              "           3.8625e-02, -6.4330e-01, -5.5846e-01,  1.1683e+00,  3.6619e-01,\n",
              "          -9.1004e-01, -8.6577e-01, -1.0390e+00, -1.2591e+00, -1.4103e+00,\n",
              "          -1.1525e+00, -2.6140e-02,  1.8443e-01,  1.2268e+00,  3.6477e-01,\n",
              "           1.3458e+00, -3.2933e-01,  1.1843e+00,  3.2383e-01,  1.0273e+00,\n",
              "          -6.9868e-01,  3.3952e-01,  1.6140e+00], requires_grad=True)),\n",
              " ('w2',\n",
              "  Parameter containing:\n",
              "  tensor([[-1.5074,  0.6582,  1.1909,  ...,  0.7734,  0.1627, -0.1330],\n",
              "          [-0.1078, -1.4610,  0.5012,  ..., -1.1195,  0.9576,  1.8190],\n",
              "          [ 0.0849, -1.4316,  1.4030,  ...,  1.2995, -0.1737, -1.0720],\n",
              "          ...,\n",
              "          [ 0.0422, -0.4631, -0.3181,  ...,  0.5446,  0.1737, -0.5834],\n",
              "          [-0.8591,  1.8435, -0.6747,  ...,  0.1216,  0.9762,  0.6557],\n",
              "          [ 1.0698, -1.1308, -0.4541,  ..., -0.4578, -1.3459,  0.6097]],\n",
              "         requires_grad=True)),\n",
              " ('b2',\n",
              "  Parameter containing:\n",
              "  tensor([ 0.3525, -1.6534, -0.1331, -0.3039, -0.7553,  0.9003,  1.8898, -0.4745,\n",
              "           0.6274, -1.7279], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "list(model.named_parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zke-9mgPNqO"
      },
      "source": [
        "Вручную обновлять значения многих параметров очень неудобно. К счастью, за нас это сделает оптимизатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OL0OtQQPNqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "854bc28e-fed4-4073-eb78-1ebe339831e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)\n",
        "print(optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDCmjddJPNqP"
      },
      "source": [
        "#### 2.1. Считаем ошибку и градиенты на одном минибатче"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnxEefCzPNqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e00516-725d-484b-9d61-3abc2154faac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(378.5316, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# получим предсказания и посчитаем ошибку\n",
        "predictions = model.forward(x)\n",
        "loss = torch.nn.functional.cross_entropy(predictions, y)\n",
        "print(loss)\n",
        "# рассчитаем градиенты и обновим параметры\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "# не забудем почистить градиенты, мы не хотим их накапливать\n",
        "optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUsrB8XsPNqP"
      },
      "source": [
        "**Задание 5 (1 балл)**: Посчитайте значение перекрёстной энтропии самостоятельно по формуле, сверьтесь с результатом выше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeLRNR7_PNqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "398ad921-7749-4c42-a324-c7b7d5c44a78"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "9.126385688781738 != 378.5315856933594",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-774eacd4d52e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mce_loss\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mce_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{ce_loss} != {loss}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: 9.126385688781738 != 378.5315856933594"
          ]
        }
      ],
      "source": [
        "# посчитайте ce_loss на основе значений переменных `predictions` и `y`\n",
        "ce_loss = torch.tensor(0.0)\n",
        "predictions = predictions.softmax(dim=1)\n",
        "for i in range(batch_size):\n",
        "    for class_num in range(10):\n",
        "        if y[i] == class_num:\n",
        "            ce_loss -= predictions[i][class_num].log()\n",
        "assert torch.allclose(ce_loss, loss), f\"{ce_loss} != {loss}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0VF7xzPPNqP"
      },
      "source": [
        "### 3. Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UKr2LsXPNqP"
      },
      "source": [
        "#### 3.1. Шаг обучения: что мы делаем с каждым минибатчем данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4KNLgxaPNqP"
      },
      "outputs": [],
      "source": [
        "def training_step(\n",
        "    batch: tuple[torch.Tensor, torch.Tensor],\n",
        "    model: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        ") -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    # прогоняем батч через модель\n",
        "    x, y = batch\n",
        "    predictions = model(x)\n",
        "    # оцениваем значение ошибки\n",
        "    loss = torch.nn.functional.cross_entropy(predictions, y)\n",
        "    # обновляем параметры\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    # возвращаем значение функции ошибки для логирования\n",
        "    return loss, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl_DLuZLPNqP"
      },
      "source": [
        "Для тестовых батчей нам не нужны градиенты, поэтому расчёты делаем внутри контекста `torch.no_grad`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z81zmxGGPNqP"
      },
      "outputs": [],
      "source": [
        "def test_step(\n",
        "    batch: tuple[torch.Tensor, torch.Tensor], model: torch.nn.Module\n",
        ") -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    x, y = batch\n",
        "    with torch.no_grad():\n",
        "        predictions = model(x)\n",
        "        # оцениваем значение ошибки\n",
        "        loss = torch.nn.functional.cross_entropy(predictions, y)\n",
        "    return loss, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KHZDRzwPNqQ"
      },
      "source": [
        "#### 3.2. А теперь: что мы хотим делать в каждой эпохе?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAyvPBYpPNqQ"
      },
      "source": [
        "**Задание 6 (2 балла)**: Напишите функцию для запуска одной эпохи (обучающей или тестовой), которая итерируется по минибатчам, обрабатывает их и в конце выводит среднюю ошибку и точность классификации. Запустите обучение на 10-15 эпох, добейтесь точности более 92% на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnKfkSd0PNqQ"
      },
      "outputs": [],
      "source": [
        "def run_epoch(\n",
        "    is_train: bool,\n",
        "    dataloader: DataLoader,\n",
        "    model: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        ") -> None:\n",
        "    # ВАШ ХОД\n",
        "\n",
        "    for batch in dataloader:\n",
        "        ...\n",
        "\n",
        "    epoch_loss = ...\n",
        "    accuracy = ...\n",
        "    print(f\"Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OgVeMGMPNqQ"
      },
      "source": [
        "Создадим модель, оптимизатор и загрузчики данных и запустим обучение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRFfLWF2PNqQ"
      },
      "outputs": [],
      "source": [
        "n_epochs = 15\n",
        "for i in range(n_epochs):\n",
        "    print(f\"Epoch {i} train:\")\n",
        "    run_epoch(True, train_loader, model, optimizer)\n",
        "    print(f\"Epoch {i} test:\")\n",
        "    run_epoch(False, test_loader, model, optimizer)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl-course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}